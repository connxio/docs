"use strict";(self.webpackChunkconnxio_docs=self.webpackChunkconnxio_docs||[]).push([[3424],{1872:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>c,contentTitle:()=>a,default:()=>g,frontMatter:()=>o,metadata:()=>r,toc:()=>h});var s=n(5893),i=n(1151);const o={sidebar_position:3},a="Batching",r={id:"integrations/transformation/batching",title:"Batching",description:"Connxio gives customers the ability to batch messages into larger single units. We do this by creating a bucket where messages are queued for a set interval until they are picked up, run through a code mapping and then sent as a single message through the pipeline. There are certain limits to batching functionality that will be explained on this page as well the process of batching itself.",source:"@site/../docs/integrations/transformation/batching.md",sourceDirName:"integrations/transformation",slug:"/integrations/transformation/batching",permalink:"/docs/integrations/transformation/batching",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:3,frontMatter:{sidebar_position:3},sidebar:"connxioSidebar",previous:{title:"Code Components",permalink:"/docs/integrations/transformation/code-components"},next:{title:"Splitting",permalink:"/docs/integrations/transformation/splitting"}},c={},h=[{value:"Limitations",id:"limitations",level:2},{value:"Creating batching code components",id:"creating-batching-code-components",level:2},{value:"Retry",id:"retry",level:2}];function l(e){const t={a:"a",blockquote:"blockquote",code:"code",em:"em",h1:"h1",h2:"h2",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",...(0,i.a)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(t.h1,{id:"batching",children:"Batching"}),"\n",(0,s.jsxs)(t.p,{children:["Connxio gives customers the ability to batch messages into larger single units. We do this by creating a bucket where messages are queued for a set interval until they are picked up, run through a ",(0,s.jsx)(t.a,{href:"/integrations/transformation/code-components",children:"code mapping"})," and then sent as a single message through the pipeline. There are certain limits to batching functionality that will be explained on this page as well the process of batching itself."]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"Batching entails waiting for messages within a set interval and then transforming said messages into a single unit before processing that unit through the Connxio pipeline"}),"\n"]}),"\n",(0,s.jsx)(t.h2,{id:"limitations",children:"Limitations"}),"\n",(0,s.jsx)(t.p,{children:"There are certain limits imposed upon the batching functionality to not overwhelm the system. These boundaries are fluent and subject to change in the future. As of now the following limits are in effect:"}),"\n",(0,s.jsxs)(t.ol,{children:["\n",(0,s.jsxs)(t.li,{children:["MaxMessageBatchCount is set to ",(0,s.jsx)(t.code,{children:"1000"})]}),"\n",(0,s.jsxs)(t.li,{children:["Connxio only supports messages below ",(0,s.jsx)(t.code,{children:"100mb"})," (see ",(0,s.jsx)(t.a,{href:"/integrations/adapters/inbound/azure-storage#Limitations",children:"Integration limitations"}),")"]}),"\n"]}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"MaxMessageBatchCount"})," is a variable that governs how many messages are possible to batch into a single message. If the bucket containing messages is larger than 1000 messages before the batching interval triggers then one message will be created per 1000 messages in the bucket. To use an example:"]}),"\n",(0,s.jsxs)(t.blockquote,{children:["\n",(0,s.jsx)(t.p,{children:"2300 messages are present in the bucket. The interval fires. Three files are created, the first and second file contains 1000 batched messages, the third file contains 300 messages."}),"\n"]}),"\n",(0,s.jsx)(t.p,{children:"This limitation is in place for a number of reasons, the first being that we want to force users to not create files too big for Connxio to handle. The seconds reason is that each batch is given its own set of resources and currently these resources have their limit set to not create files that will overwhelm external and internal systems. We do have future plans to support large files above 100mb, contact us for more information."}),"\n",(0,s.jsx)(t.h2,{id:"creating-batching-code-components",children:"Creating batching code components"}),"\n",(0,s.jsxs)(t.p,{children:["When implementing batching into your integration the first step is to create the code that joins your messages together into a cohesive whole. This is done in more or less the same way as ",(0,s.jsx)(t.a,{href:"/integrations/transformation/code-components",children:"map code components"})," but with a few key differences."]}),"\n",(0,s.jsx)(t.p,{children:"Firstly you need to create the batching code itself, see the map components page for a simple rundown of the process, but instead of using the boiler plate detailed for maps you use the one detailed below:"}),"\n",(0,s.jsx)(t.pre,{children:(0,s.jsx)(t.code,{className:"language-csharp",children:"public class MyFirstBatcher : IConnXioBatch\n{\n    public TransformationContext Batch(IEnumerable<TransformationContext> transformationContexts)\n    {\n        var msgIns = new List<MsgIn>();\n\n        //Make list of objects instead of bytes\n        foreach (var transformationContext in transformationContexts)\n        {\n            msgIns.Add(JsonConvert.DeserializeObject<MsgIn>(transformationContext.Content));\n        }\n\n        //Create new outbound message\n        var msgOut = new MsgOut();\n\n        //Add content to new message\n        msgOut.Type = msgIns[0].Type;\n        msgOut.Values = new List<string>();\n\n        foreach (var msg in msgIns)\n        {\n            msgOut.Values.Add(msg.Value);\n        }\n\n        TransformationContext outTransformationContext = new TransformationContext\n        {\n            Content = JsonConvert.SerializeObject(msgOut),\n            MetaData = transformationContexts.First().MetaData.Copy()\n        };\n\n        //Return message as string\n        return outTransformationContext;\n    }\n}\n"})}),"\n",(0,s.jsxs)(t.p,{children:[(0,s.jsx)(t.strong,{children:"Upload the component"})," by using the methods described on the ",(0,s.jsx)(t.a,{href:"/integrations/transformation/code-components",children:"code components page"}),". Remember to choose the ",(0,s.jsx)(t.em,{children:"batching"})," type."]}),"\n",(0,s.jsx)(t.h2,{id:"retry",children:"Retry"}),"\n",(0,s.jsxs)(t.p,{children:["Batching has multiple retry patterns that differ based on which step of the batching process that fails. If the process fails on transient errors before running the batching code component the system puts messages back in queue and tries again 60 seconds later. If the failure is happens after running the batching code the algorithm tries to send the message multiple times with increasing delay until the message is scheduled for retry through the ",(0,s.jsx)(t.a,{href:"/integrations/retry",children:"disaster pipeline"}),"."]}),"\n",(0,s.jsx)(t.p,{children:"Retry can end up sending smaller files than anticipated. If you experience problems like this, your logging provider should have received warnings about the fault, if not please contact your representative."})]})}function g(e={}){const{wrapper:t}={...(0,i.a)(),...e.components};return t?(0,s.jsx)(t,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},1151:(e,t,n)=>{n.d(t,{Z:()=>r,a:()=>a});var s=n(7294);const i={},o=s.createContext(i);function a(e){const t=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(t):{...t,...e}}),[t,e])}function r(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:a(e.components),s.createElement(o.Provider,{value:t},e.children)}}}]);